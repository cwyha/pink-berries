{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# I. Getting Started\n",
    "\n",
    "Start by creating a snapshot from the Pink Berries Metagenome snapshot, and starting a CeruleanTools AMI Instance with that volume loaded onto it.\n",
    "\n",
    "You have to make a directory for the drive and mount the drive. My metagenome data volume was at `/dev/xvdc`; I'm not sure how to tell where it will be. If you make a snapshot in the right zone (e.g. us-east-1d), you can also load and mount the volume directly from your instance:\n",
    "\n",
    "```\n",
    "mkdir data\n",
    "\n",
    "aws ec2 attach-volume --volume-id vol-0bdfad3677d717075 --instance-id i-0a62227ff1d1977bd --device /dev/xvdh\n",
    "\n",
    "sudo mount /dev/xvdh ~/data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/ubuntu/data’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!lsblk\n",
    "!mkdir ~/data\n",
    "!sudo mount /dev/xvdf ~/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Inputs and pre-processing\n",
    "\n",
    "Cerulean requires that we use *ABySS* to assemble contigs from our short reads, and then map the PacBio long reads to the contigs using *BLASR*. \n",
    "\n",
    "First, create a folder in which to store working files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cd\n",
    "!mkdir hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABySS: assembling short-read contigs\n",
    "\n",
    "We'll do two assemblies: \n",
    "* **illumina_4moleculo + pacbio** - paired-end read prepped for moleculo mapped onto pacbio long reads (using illumina instead of pacbio assembly because this library had deeper coverage.\n",
    "* **illumina_4moleculo + moleculo** paired-end read prepped for moleculo, but mapped onto moleculo long reads instead of pacbio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "To start, we copy the Illumina short-read files in our new directory. Binning found both alphaproteobacteria (\"a\" prefix) and bacteroidetes (\"b\" prefix)--we only want to copy over the bacteroidetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cp -R ~/data/metagenomes/sequence_reads/illumina_4moleculo/quality-trimmed-reads/reads-by-genome/b* ~/hybrid/reads-by-genome/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ABySS pre-processing\n",
    "\n",
    "**Deinterleaving:** These are interleaved files. To deinterleave each of them, run the following:\n",
    "```\n",
    "cd ~/hybrid/reads-by-genome/\n",
    "mkdir ~/hybrid/deinterleaved\n",
    "for FILE in *; do \n",
    "mkdir ~/hybrid/deinterleaved/$FILE-deinterleaved;\n",
    "grep -A1 \"_1$\" \"$FILE\" | grep -v \"^--$\" >  ~/hybrid/deinterleaved/$FILE-deinterleaved/reads-1.fasta; \n",
    "grep -A1 \"_2$\" \"$FILE\" | grep -v \"^--$\" >  ~/hybrid/deinterleaved/$FILE-deinterleaved/reads-2.fasta; \n",
    "done\n",
    "```\n",
    "\n",
    "Depending on what the files are named, it might be good to tweak the above to give more sensible names to your folders. I did this manually. However, you probably want to keep the name of each pair of files within each folder the same: reads-1 and reads-2. This makes the assembly step simpler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naming reads properly**: ABySS also needs each read to be named with a slash. While in the directory containing the folders for each binned OTU (i.e. ~/hybrid/deinterleaved), the following will replace the\n",
    "\n",
    "    hyphens (e.g. DJB775P1:392:D1R59ACXX:2:1310:17052:38927-2)\n",
    "    with slashes (--> DJB775P1:392:D1R59ACXX:2:1310:17052:38927/2)\n",
    "\n",
    "\n",
    "The -i flag is required to write the results of sed to a file (.bak is necessary for compatibility with certain systems). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cd ~/hybrid/deinterleaved/\n",
    "!for FOLDER in * ; do for FILE in $FOLDER/*; do sed -i.bak 's/_2/\\/2/' $FILE; sed -i.bak 's/_1/\\/1/' $FILE; done; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command creates some extraneous .bak files. Delete them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cd ~/hybrid/deinterleaved/\n",
    "!for FOLDER in * ; do rm $FOLDER/*.bak; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reverse-complementing (binned reads only):** Due to the binning process, the binned reads are in a forward-forward read format, i.e. both paired-end reads are both from 5' to 3'. (For more conceptual information on this, see http://www.cureffi.org/2012/12/19/forward-and-reverse-reads-in-paired-end-sequencing/.) \n",
    "\n",
    "However, ABySS needs them to be in forward-reverse format, i.e. for each paired read, one needs to be reverse-complemented. We'll use Biopython to reverse-complement the reads.\n",
    "\n",
    "Install Biopython using pip:\n",
    "\n",
    "    pip install biopython\n",
    "\n",
    "Then run the following python script in each binned folder to reverse-complement the `reads-2` files. Any lines that say \"print\" can be commented out if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reverse-complementing the reads in a fasta file, reads-2.fasta\n",
    "#To be run within the folder in which each reads-2 file is located \n",
    "\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "\n",
    "rc_file = open(\"rc-reads-2.fasta\", \"w+\") #w opens file for writing; \n",
    "                                         #+ creates if it doesn't exist\n",
    "\n",
    "for seq_record in SeqIO.parse(\"reads-2.fasta\", \"fasta\"):\n",
    "    print(\"Reverse-complementing: \"+seq_record.id)\n",
    "    #print(\"ORIGINAL: \" + seq_record.seq)\n",
    "    seqRC = seq_record.reverse_complement(id=True) #preserves seq ID\n",
    "    #print(\"REV-COMP: \" + seqRC.seq)\n",
    "    print(\"Reverse-complementing complete! \") #+ seqRC.id + \"\\n\")\n",
    "    \n",
    "    #write new record to file\n",
    "    rc_file.write(\">\"+str(seqRC.id))\n",
    "    rc_file.write(\"\\n\")\n",
    "    rc_file.write(str(seqRC.seq))\n",
    "    rc_file.write(\"\\n\")\n",
    "\n",
    "rc_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ABySS Assembly\n",
    "\n",
    "Now, assemble the contigs. The flag k=64 is the maximum k-mer length. It's probably a good idea to run this in a screen. To check on what processes are happening, use `top` (and `q` to quit)\n",
    "\n",
    "In the binned case, I preferred doing this individually for each bacteroidetes bin so I could specify a different name for each file:\n",
    "\n",
    "```\n",
    "cd ~/hybrid/deinterleaved/b1_flavo_deinterleaved\n",
    "abyss-pe name=b1-flavo k=64 in='reads-1.fasta reads-2.fasta'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-49513709daa1>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-49513709daa1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    cd ~/hybrid/hiseq.raw.fastq\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This will generate 2 files used for inputs to Cerulean:\n",
    "```\n",
    "* <dataname>-contigs.fa    #This contains the contig sequences\n",
    "* <dataname>-contigs.dot   #This contains the graph structure\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map PacBio reads to ABySS contigs using BLASR\n",
    "\n",
    "Note: sawriter and blasr are part of SMRT Analysis toolkit\n",
    "\n",
    "Note: You need to set the environmental variables and path:\n",
    "   \n",
    "```\n",
    "$ export SEYMOUR_HOME=/opt/smrtanalysis/\n",
    "$ source $SEYMOUR_HOME/etc/setup.sh\n",
    "```\n",
    "   \n",
    "Suppose PacBio reads are stored in `<dataname>_pacbio.fasta`\n",
    "\n",
    "```\n",
    "$ sawriter <dataname>-contigs.fa\n",
    "$ blasr <dataname>_pacbio.fa <dataname>-contigs.fa -minMatch 10 \\\n",
    "     -minPctIdentity 70 -bestn 30 -nCandidates 30 -maxScore -500 \\\n",
    "     -nproc <numthreads> -noSplitSubreads \\\n",
    "     -out <dataname>_pacbio_contigs_mapping.fasta.m4\n",
    "```\n",
    "   \n",
    "   Make sure the fasta.m4 file generated has the following format:\n",
    "   qname tname qstrand tstrand score pctsimilarity tstart tend tlength \\\n",
    "   qstart qend qlength ncells\n",
    "   The file format may be verified by adding the option -header to blasr. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Cerulean\n",
    "\n",
    " Cerulean requires that all input files are in the same directory `<basedir>`:\n",
    " i)   `<basedir>/<dataname>-contigs.fa`\n",
    " ii)  `<basedir>/<dataname>-contigs.dot`\n",
    " iii) `<basedir>/<dataname>_pacbio_contigs_mapping.fasta.m4`\n",
    "\n",
    " To run:\n",
    " ```\n",
    " $ python src/Cerulean.py --dataname <dataname> --basedir <basedir> \\\n",
    " --nproc <numthreads>\n",
    " ```\n",
    " \n",
    " This will generate:\n",
    " i)  `<basedir>_cerulean.fasta`\n",
    " ii) `<basedir>_cerulean.dot`\n",
    " Note: The dot does not have same contigs as fasta, but intermediate graph.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing\n",
    "\n",
    " Currently Cerulean does not include consensus sequence of PacBio reads in gaps\n",
    " The gaps may be filled using PBJelly.\n",
    " ```\n",
    " $ python $JELLYPATH/fakeQuals.py <dataname>_cerulean.fasta <dataname>_cerulean.qual\n",
    " $ python $JELLYPATH/fakeQuals.py <dataname>_pacbio.fasta <dataname>_pacbio.qual\n",
    " $ cp $JELLYPATH/lambdaExample/Protocol.xml .\n",
    " $ mkdir PBJelly\n",
    " ```\n",
    " \n",
    " Modify Protocol.xml as follows:\n",
    " Set `<reference>` to `$PATH_TO_<basedir>/<dataname>_cerulean.fasta`\n",
    " Set `<outputDir>` to `$PATH_TO_<basedir>/PBJelly`\n",
    " Set `<baseDir>` to `$PATH_TO_<basedir>`\n",
    " Set `<job>` to `<dataname>_pacbio.fasta`\n",
    " Set `<blasr>` option `-nproc <numthreads>`\n",
    " \n",
    " Note: PBJelly requires that the suffix be .fasta and not .fa\n",
    " Next run PBJelly:\n",
    " \n",
    " ```\n",
    " ($ source $JELLYPATH/exportPaths.sh)\n",
    " $ python $JELLYPATH/Jelly.py <stage> Protocol.xml\n",
    " ```\n",
    " \n",
    " where <stage> has to be in the order:\n",
    " ```\n",
    " setup\n",
    " mapping\n",
    " support\n",
    " extraction\n",
    " assembly\n",
    " output\n",
    " ```\n",
    " \n",
    " The assembled contigs may be view in \n",
    " ```\n",
    " <basedir>/PBJelly/assembly/jellyOutput.fasta\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to quality test against other assemblies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
