{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Getting Started\n",
    "\n",
    "Start by creating a snapshot from the Pink Berries Metagenome snapshot, and starting a CeruleanTools AMI Instance with that volume loaded onto it.\n",
    "\n",
    "You'll have to make a directory for the drive and mount the drive. My metagenome data volume was at `/dev/xvdc`; you can find this by using `lsblk` and seeing which name corresponds to your unmounted volume (MOUNTPOINT is blank)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME  MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT\n",
      "xvdb  202:16   0  200G  0 disk /mnt\n",
      "xvda1 202:1    0  100G  0 disk /\n",
      "mkdir: cannot create directory ‘/home/ubuntu/data’: File exists\n",
      "mount: mount point data does not exist\n"
     ]
    }
   ],
   "source": [
    "!lsblk\n",
    "!mkdir ~/data\n",
    "!sudo mount /dev/xvdf ~/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binning\n",
    "\n",
    "Use BWA or Bowtie to just look at *Bacteroidetes*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs and pre-processing\n",
    "\n",
    "Cerulean requires that we use *ABySS* to assemble contigs from our short reads, and then map the PacBio long reads to the contigs using *BLASR*. \n",
    "\n",
    "First, we'll create a folder in which to store our working files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘hybrid’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!cd\n",
    "!mkdir hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembling short-read contigs\n",
    "\n",
    "To start, place the Illumina short-read files in our new directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! need to find where the illumina files are and move them to ~/hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, assemble the contigs: (\"   If the paired-end reads are stored in fastq format in the files `reads1.fastq` and `reads2.fastq`, then contigs may be assembled by:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! $ abyss-pe k=64 n=10 in='reads1.fastq reads2.fastq' name=<dataname>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This will generate 2 files used for inputs to Cerulean:\n",
    "```\n",
    "* <dataname>-contigs.fa    #This contains the contig sequences\n",
    "* <dataname>-contigs.dot   #This contains the graph structure\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map PacBio reads to ABySS contigs using BLASR\n",
    "\n",
    "   Note: sawriter and blasr are part of SMRT Analysis toolkit\n",
    "   Note: You need to set the environmental variables and path:\n",
    "   \n",
    "```\n",
    "$ export SEYMOUR_HOME=/opt/smrtanalysis/\n",
    "$ source $SEYMOUR_HOME/etc/setup.sh\n",
    "```\n",
    "   \n",
    "Suppose PacBio reads are stored in `<dataname>_pacbio.fasta`\n",
    "\n",
    "```\n",
    "$ sawriter <dataname>-contigs.fa\n",
    "$ blasr <dataname>_pacbio.fa <dataname>-contigs.fa -minMatch 10 \\\n",
    "     -minPctIdentity 70 -bestn 30 -nCandidates 30 -maxScore -500 \\\n",
    "     -nproc <numthreads> -noSplitSubreads \\\n",
    "     -out <dataname>_pacbio_contigs_mapping.fasta.m4\n",
    "```\n",
    "   \n",
    "   Make sure the fasta.m4 file generated has the following format:\n",
    "   qname tname qstrand tstrand score pctsimilarity tstart tend tlength \\\n",
    "   qstart qend qlength ncells\n",
    "   The file format may be verified by adding the option -header to blasr. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Cerulean\n",
    "\n",
    " Cerulean requires that all input files are in the same directory `<basedir>`:\n",
    " i)   `<basedir>/<dataname>-contigs.fa`\n",
    " ii)  `<basedir>/<dataname>-contigs.dot`\n",
    " iii) `<basedir>/<dataname>_pacbio_contigs_mapping.fasta.m4`\n",
    "\n",
    " To run:\n",
    " ```\n",
    " $ python src/Cerulean.py --dataname <dataname> --basedir <basedir> \\\n",
    " --nproc <numthreads>\n",
    " ```\n",
    " \n",
    " This will generate:\n",
    " i)  `<basedir>_cerulean.fasta`\n",
    " ii) `<basedir>_cerulean.dot`\n",
    " Note: The dot does not have same contigs as fasta, but intermediate graph.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing\n",
    "\n",
    " Currently Cerulean does not include consensus sequence of PacBio reads in gaps\n",
    " The gaps may be filled using PBJelly.\n",
    " ```\n",
    " $ python $JELLYPATH/fakeQuals.py <dataname>_cerulean.fasta <dataname>_cerulean.qual\n",
    " $ python $JELLYPATH/fakeQuals.py <dataname>_pacbio.fasta <dataname>_pacbio.qual\n",
    " $ cp $JELLYPATH/lambdaExample/Protocol.xml .\n",
    " $ mkdir PBJelly\n",
    " ```\n",
    " \n",
    " Modify Protocol.xml as follows:\n",
    " Set `<reference>` to `$PATH_TO_<basedir>/<dataname>_cerulean.fasta`\n",
    " Set `<outputDir>` to `$PATH_TO_<basedir>/PBJelly`\n",
    " Set `<baseDir>` to `$PATH_TO_<basedir>`\n",
    " Set `<job>` to `<dataname>_pacbio.fasta`\n",
    " Set `<blasr>` option `-nproc <numthreads>`\n",
    " \n",
    " Note: PBJelly requires that the suffix be .fasta and not .fa\n",
    " Next run PBJelly:\n",
    " \n",
    " ```\n",
    " ($ source $JELLYPATH/exportPaths.sh)\n",
    " $ python $JELLYPATH/Jelly.py <stage> Protocol.xml\n",
    " ```\n",
    " \n",
    " where <stage> has to be in the order:\n",
    " ```\n",
    " setup\n",
    " mapping\n",
    " support\n",
    " extraction\n",
    " assembly\n",
    " output\n",
    " ```\n",
    " \n",
    " The assembled contigs may be view in \n",
    " ```\n",
    " <basedir>/PBJelly/assembly/jellyOutput.fasta\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to quality test against other assemblies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
